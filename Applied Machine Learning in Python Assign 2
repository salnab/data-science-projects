def answer_one():
    from sklearn.linear_model import LinearRegression
    from sklearn.preprocessing import PolynomialFeatures
    from sklearn.pipeline import make_pipeline
    import numpy as np

    x_t = np.linspace(0,10,100)
    predlist = []
    
    for i in [1,3,6,9]:
        model = make_pipeline(PolynomialFeatures(i), LinearRegression())
        model = model.fit(X_train[:, np.newaxis], y_train)
        predlist.append(model.predict(x_t[:, np.newaxis]))
    return np.array(predlist)
answer_one()

def answer_two():
    from sklearn.linear_model import LinearRegression
    from sklearn.preprocessing import PolynomialFeatures
    from sklearn.metrics.regression import r2_score
    from sklearn.pipeline import make_pipeline

    x_t = np.linspace(0,10,100)
    R2score_training = []
    R2score_test = []
    
    for i in range(0,10):
        model = make_pipeline(PolynomialFeatures(i), LinearRegression())
        model = model.fit(X_train[:, np.newaxis], y_train)
        pred_train = model.predict(X_train[:, np.newaxis])
        pred_test = model.predict(X_test[:, np.newaxis])
        R2score_training.append(r2_score(pred_train, y_train))
        R2score_test.append(r2_score(pred_test, y_test))
    return np.array(R2score_training), np.array(R2score_test)
answer_two()

def answer_three():
    
    y = []
    y = answer_two()
    y_train = y[0].tolist()
    y_test = y[1].tolist()
    degree = range(0,10)
    
    #import matplotlib.pyplot as plt
    #%matplotlib notebook
    #plt.figure(figsize=(10,5))
    #plt.plot(degree, y_train, 'o', label='training data', markersize=10)
    #plt.plot(degree, y_test, 'o', label='test data', markersize=10)
    #plt.ylim(-8,1.5)
    #plt.legend(loc=4)
    
    r2train_max = max(y_train)
    Overfitting = y_train.index(r2train_max)
    r2train_min = min(y_train)
    Underfitting_train = y_train.index(r2train_min)
    r2test_min = min(y_test)
    Underfitting = y_test.index(r2test_min)
    r2test_max = max(y_test)
    Good_Generalization = y_test.index(r2test_max)
    
    return Underfitting, Overfitting, Good_Generalization
answer_three()

def answer_four():
    from sklearn.preprocessing import PolynomialFeatures
    from sklearn.linear_model import Lasso, LinearRegression
    from sklearn.metrics.regression import r2_score

    X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)
    linreg = LinearRegression().fit(X_train.reshape(-1,1), y_train)
    linreg_pred = linreg.predict(X_test.reshape(-1,1))
    LinearRegression_R2_test_score = r2_score(linreg_pred, y_test)
    
    poly = PolynomialFeatures(12)
    x_poly = poly.fit_transform(x)
    X_trainpoly, X_testpoly, y_trainpoly, y_testpoly = train_test_split(x_poly, y, random_state=0)
    regu_linreg = Lasso(alpha=0.01, max_iter=10000).fit(X_trainpoly, y_trainpoly)
    regu_linreg_pred = regu_linreg.predict(X_testpoly)
    Lasso_R2_test_score = r2_score(regu_linreg_pred, y_testpoly)

    return LinearRegression_R2_test_score, Lasso_R2_test_score
answer_four()
